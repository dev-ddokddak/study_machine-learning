{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a2f5e5",
   "metadata": {},
   "source": [
    "### 👀교차 검증(Cross Validation)\n",
    "- 기존 방식에서는 데이터 세트에서 학습 데이터 세트와 테스트 데이터 세트를 분리한 뒤 모델 검증을 진행한다.\n",
    "- 교차 검증 시, 학습 데이터를 다시 분할하여 학습 데이터와 모델 성능을 1차 평가하는 검증 데이터로 나눈다.\n",
    "<img src=\"./images/cross_validation01.png\" width=\"500\" style=\"margin-left: -30px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c94d94",
   "metadata": {},
   "source": [
    "### 교차 검증의 종류\n",
    "##### K-Fold\n",
    "- k개의 데이터 폴드 세트를 만든 뒤 k번만큼 학습과 검증 평가를 반복하여 수행하는 방식.\n",
    "- 학습 데이터와 검증 데이터를 정확히 자르기 때문에 타겟 데이터의 비중이 한 곳으로 치중될 수 있다.\n",
    "- 예를 들어, 0, 1, 2, 중에서 0, 1, 두 가지만 잘라서 검증하게 되면 다른 하나의 타겟 데이터를 예측할 수 없게 된다.\n",
    "- Stratified K-Fold로 해결한다.\n",
    "##### Stratified K-Fold\n",
    "- K-Fold와 마찬가지로 k번 수행하지만, 폴드 세트를 만들 때 학습 데이터 세트와 검증 데이터 세트가 가지는 타겟 분포도가 유사하도록 검증한다.\n",
    "- 타겟 데이터의 비중을 항상 똑같게 자르기 때문에 데이터가 한 곳으로 치중되는 것을 방지한다.\n",
    "<img src=\"./images/cross_validation02.png\" width=\"500\" style=\"margin-top:20px; margin-bottom:20px; margin-left: -30px\">\n",
    "##### GridSearchCV\n",
    "- 교차 검증과 최적의 하이퍼 파라미터 튜닝을 한 번에 할 수 있는 객체이다.\n",
    "- max_depth와 min_samples_split에 1차원 정수형 list를 전달하면, 2차원으로 결합하여 격자(Grid)를 만들고, 이 중 최적의 점을 찾아낸다.\n",
    "- 딥러닝에서는 학습 속도가 머신러닝에 비해 느리고, 레이어(층)가 깊어질 수록 조정해주어야 할 하이퍼 파라미터 값이 많아지기 때문에, RandomSearchCV에서 대략적인 범위를 찾은 다음, GridSearchCV로 디테일을 조정하는 방식을 사용한다.\n",
    "<img src=\"./images/grid_search_cv.png\" width=\"500\" style=\"margin-top: 20px; margin-left: -30px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b1612",
   "metadata": {},
   "source": [
    "##### 붓꽃 데이터로 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b8b325d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0         50\n",
       "1         50\n",
       "2         50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "features, targets = iris.data, iris.target\n",
    "\n",
    "target_df = pd.DataFrame(targets, columns=['target'])\n",
    "target_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351f7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(min_samples_leaf=6, random_state=124)\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571239c",
   "metadata": {},
   "source": [
    "##### KFold.split(feature)\n",
    "- features만 전달하고 학습용, 검증용 행 번호를 array로 리턴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e13ec2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "================================================================================\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "================================================================================\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "================================================================================\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "================================================================================\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kfold.split(features):\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5af82448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 1 교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 학습 타겟 데이터 분포: \n",
      "1    50\n",
      "2    50\n",
      "0    20\n",
      "Name: count, dtype: int64\n",
      "#1 검증 타겟 데이터 분포: \n",
      "0    30\n",
      "Name: count, dtype: int64\n",
      "#1 학습 세트 인덱스: [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#1 검증 세트 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "====================================================================================================\n",
      "\n",
      "# 2 교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 학습 타겟 데이터 분포: \n",
      "2    50\n",
      "1    40\n",
      "0    30\n",
      "Name: count, dtype: int64\n",
      "#2 검증 타겟 데이터 분포: \n",
      "0    20\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "#2 학습 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#2 검증 세트 인덱스: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "====================================================================================================\n",
      "\n",
      "# 3 교차 검증 정확도: 0.8333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 학습 타겟 데이터 분포: \n",
      "0    50\n",
      "2    50\n",
      "1    20\n",
      "Name: count, dtype: int64\n",
      "#3 검증 타겟 데이터 분포: \n",
      "1    30\n",
      "Name: count, dtype: int64\n",
      "#3 학습 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#3 검증 세트 인덱스: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "====================================================================================================\n",
      "\n",
      "# 4 교차 검증 정확도: 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 학습 타겟 데이터 분포: \n",
      "0    50\n",
      "1    40\n",
      "2    30\n",
      "Name: count, dtype: int64\n",
      "#4 검증 타겟 데이터 분포: \n",
      "2    20\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "#4 학습 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#4 검증 세트 인덱스: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "====================================================================================================\n",
      "\n",
      "# 5 교차 검증 정확도: 0.8333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 학습 타겟 데이터 분포: \n",
      "0    50\n",
      "1    50\n",
      "2    20\n",
      "Name: count, dtype: int64\n",
      "#5 검증 타겟 데이터 분포: \n",
      "2    30\n",
      "Name: count, dtype: int64\n",
      "#5 학습 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "#5 검증 세트 인덱스: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "====================================================================================================\n",
      "▶ 평균 검증 정확도: 0.91998\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    count += 1\n",
    "    \n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "    \n",
    "    train_targets = pd.DataFrame(y_train)\n",
    "    test_targets = pd.DataFrame(y_test)\n",
    "    \n",
    "    #학습 및 예측\n",
    "    decision_tree_classifier.fit(X_train, y_train)\n",
    "    prediction = decision_tree_classifier.predict(X_test)\n",
    "    \n",
    "    # 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, prediction), 4)\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(f\"\\n# {count} 교차 검증 정확도: {accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기: {test_size}\")\n",
    "    print(f\"#{count} 학습 타겟 데이터 분포: \\n{train_targets.value_counts()}\")\n",
    "    print(f\"#{count} 검증 타겟 데이터 분포: \\n{test_targets.value_counts()}\")\n",
    "    print(f\"#{count} 학습 세트 인덱스: {train_index}\")\n",
    "    print(f\"#{count} 검증 세트 인덱스: {test_index}\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "# 폴드 별 검증 정확도를 합하여 평균 정확도 계산\n",
    "print(f\"▶ 평균 검증 정확도: {np.mean(cv_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc685a0d",
   "metadata": {},
   "source": [
    "##### 타겟 데이터의 분포를 동일하게 교차 검증 진행\n",
    "\n",
    "##### StratifiedFold.split(features, targets)\n",
    "- features와 targets 모두 전달하고 학습용, 검증용 행 번호를 array로 리턴한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5b5f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(min_samples_leaf=6, random_state=124)\n",
    "\n",
    "# 5개의 폴드 세트로 분리\n",
    "skfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "202086ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 1 교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "#1 검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "#1 학습 세트 인덱스: [ 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#1 검증 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57\n",
      "  58  59 100 101 102 103 104 105 106 107 108 109]\n",
      "====================================================================================================\n",
      "\n",
      "# 2 교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "#2 검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "#2 학습 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#2 검증 세트 인덱스: [ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67\n",
      "  68  69 110 111 112 113 114 115 116 117 118 119]\n",
      "====================================================================================================\n",
      "\n",
      "# 3 교차 검증 정확도: 0.9, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "#3 검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "#3 학습 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#3 검증 세트 인덱스: [ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77\n",
      "  78  79 120 121 122 123 124 125 126 127 128 129]\n",
      "====================================================================================================\n",
      "\n",
      "# 4 교차 검증 정확도: 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "#4 검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "#4 학습 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 140 141 142 143 144 145 146 147 148 149]\n",
      "#4 검증 세트 인덱스: [ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87\n",
      "  88  89 130 131 132 133 134 135 136 137 138 139]\n",
      "====================================================================================================\n",
      "\n",
      "# 5 교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "#5 검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "#5 학습 세트 인덱스: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136 137 138 139]\n",
      "#5 검증 세트 인덱스: [ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97\n",
      "  98  99 140 141 142 143 144 145 146 147 148 149]\n",
      "====================================================================================================\n",
      "▶ 평균 검증 정확도: 0.94002\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, test_index in skfold.split(features, targets):\n",
    "    count += 1\n",
    "    \n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "    \n",
    "    train_targets = pd.DataFrame(y_train)\n",
    "    test_targets = pd.DataFrame(y_test)\n",
    "    \n",
    "    #학습 및 예측\n",
    "    decision_tree_classifier.fit(X_train, y_train)\n",
    "    prediction = decision_tree_classifier.predict(X_test)\n",
    "    \n",
    "    # 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test, prediction), 4)\n",
    "    \n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print(f\"\\n# {count} 교차 검증 정확도: {accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기: {test_size}\")\n",
    "    print(f\"#{count} 학습 타겟 데이터 분포: \\n{train_targets.value_counts()}\")\n",
    "    print(f\"#{count} 검증 타겟 데이터 분포: \\n{test_targets.value_counts()}\")\n",
    "    print(f\"#{count} 학습 세트 인덱스: {train_index}\")\n",
    "    print(f\"#{count} 검증 세트 인덱스: {test_index}\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "# 폴드 별 검증 정확도를 합하여 평균 정확도 계산\n",
    "print(f\"▶ 평균 검증 정확도: {np.mean(cv_accuracy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc9a98",
   "metadata": {},
   "source": [
    "##### 편하게 수행할 수 있는 교차 검증\n",
    "\n",
    "##### cross_val_score(estimator, x, y, cv, scoring)\n",
    "- estimator: classifier 종류 모델이면 내부적으로 stratified K-Fold로 진행된다.\n",
    "- x: featuers\n",
    "- y: targets\n",
    "- scoring: 평가 함수, 정확도(accuracy)외에 다른 것은 다른 장에서 배운다.\n",
    "- cv: 폴드 세트 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9d62b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도: [0.96666667 0.96666667 0.9        0.86666667 1.        ]\n",
      "평균 정확도: 0.9400000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=124, min_samples_leaf=6)\n",
    "\n",
    "features, targets = iris.data, iris.target\n",
    "\n",
    "score = cross_val_score(decision_tree_classifier, features, targets, scoring='accuracy', cv=5)\n",
    "print('교차 검증별 정확도: {}'.format(score))\n",
    "print('평균 정확도: {}'.format(np.mean(score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba2774",
   "metadata": {},
   "source": [
    "#### GridSearchCV(estimator, param_grid, cv, refit, return_train_score)\n",
    "- estimator: 학습할 모델 객체 작성\n",
    "- param_grid: dict형태로 전달해야 하며, 주요 key값은 max_depth, min_samples_split이다.\n",
    "- cv: 폴드 세트 개수\n",
    "- refit: 최적의 하이퍼 파라미터로 전달한 모델 객체를 다시 훈련하고자 할 때 True를 전달한다, 디폴트는 True.\n",
    "- return_train_score: 교차 검증 점수를 가져올 지에 대해 True 또는 False를 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc7f275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 데이터를 분리한다.\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=124)\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# max_depth: 노드가 생성되는 최대 깊이 수 제한\n",
    "# min_sample_split: 최소 샘플 개수 제한\n",
    "parameters = {'max_depth': [2, 3, 4], 'min_samples_split': [6, 7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "295e7d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4], &#x27;min_samples_split&#x27;: [6, 7]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4], &#x27;min_samples_split&#x27;: [6, 7]},\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [2, 3, 4], 'min_samples_split': [6, 7]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_decision_tree_classifier = GridSearchCV(decision_tree_classifier\n",
    "                                             , param_grid=parameters\n",
    "                                             , cv=3\n",
    "                                             , refit=True\n",
    "                                             , return_train_score=True)\n",
    "\n",
    "grid_decision_tree_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "274fc7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00033267, 0.00066789, 0.00132505, 0.00066511, 0.00064429,\n",
       "        0.00099881]),\n",
       " 'std_fit_time': array([0.00047047, 0.00047228, 0.00047228, 0.00047031, 0.00045564,\n",
       "        0.00081449]),\n",
       " 'mean_score_time': array([0.00033172, 0.00099579, 0.00033545, 0.0006636 , 0.00034245,\n",
       "        0.00065128]),\n",
       " 'std_score_time': array([4.69122522e-04, 5.28599076e-06, 4.74404927e-04, 4.69235560e-04,\n",
       "        4.84295387e-04, 4.60818249e-04]),\n",
       " 'param_max_depth': masked_array(data=[2, 2, 3, 3, 4, 4],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[6, 7, 6, 7, 6, 7],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 2, 'min_samples_split': 6},\n",
       "  {'max_depth': 2, 'min_samples_split': 7},\n",
       "  {'max_depth': 3, 'min_samples_split': 6},\n",
       "  {'max_depth': 3, 'min_samples_split': 7},\n",
       "  {'max_depth': 4, 'min_samples_split': 6},\n",
       "  {'max_depth': 4, 'min_samples_split': 7}],\n",
       " 'split0_test_score': array([0.975, 0.95 , 0.95 , 1.   , 0.95 , 1.   ]),\n",
       " 'split1_test_score': array([0.975, 0.975, 0.975, 0.975, 0.975, 0.975]),\n",
       " 'split2_test_score': array([0.975, 0.975, 1.   , 1.   , 1.   , 1.   ]),\n",
       " 'mean_test_score': array([0.975     , 0.96666667, 0.975     , 0.99166667, 0.975     ,\n",
       "        0.99166667]),\n",
       " 'std_test_score': array([0.        , 0.01178511, 0.02041241, 0.01178511, 0.02041241,\n",
       "        0.01178511]),\n",
       " 'rank_test_score': array([3, 6, 3, 1, 3, 1]),\n",
       " 'split0_train_score': array([0.975 , 0.975 , 0.9875, 1.    , 0.9875, 1.    ]),\n",
       " 'split1_train_score': array([0.975, 0.975, 1.   , 1.   , 1.   , 1.   ]),\n",
       " 'split2_train_score': array([0.975, 0.975, 1.   , 1.   , 1.   , 1.   ]),\n",
       " 'mean_train_score': array([0.975     , 0.975     , 0.99583333, 1.        , 0.99583333,\n",
       "        1.        ]),\n",
       " 'std_train_score': array([0.        , 0.        , 0.00589256, 0.        , 0.00589256,\n",
       "        0.        ])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_decision_tree_classifier.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acf09fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 6}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 7}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>6</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 6}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 7}</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 6}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 7}</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 2, 'min_samples_split': 6}         0.975000                3   \n",
       "1  {'max_depth': 2, 'min_samples_split': 7}         0.966667                6   \n",
       "2  {'max_depth': 3, 'min_samples_split': 6}         0.975000                3   \n",
       "3  {'max_depth': 3, 'min_samples_split': 7}         0.991667                1   \n",
       "4  {'max_depth': 4, 'min_samples_split': 6}         0.975000                3   \n",
       "5  {'max_depth': 4, 'min_samples_split': 7}         0.991667                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.975              0.975              0.975  \n",
       "1              0.950              0.975              0.975  \n",
       "2              0.950              0.975              1.000  \n",
       "3              1.000              0.975              1.000  \n",
       "4              0.950              0.975              1.000  \n",
       "5              1.000              0.975              1.000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores_df = pd.DataFrame(grid_decision_tree_classifier.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb0b8f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 7}\n",
      "GridSearchCV 최고 정확도: 0.9916666666666667\n",
      "테스트 데이터 세트 정확도: 0.9\n",
      "테스트 데이터 세트 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "print(f'GridSearchCV 최적 파라미터: {grid_decision_tree_classifier.best_params_}')\n",
    "print(f'GridSearchCV 최고 정확도: {grid_decision_tree_classifier.best_score_}')\n",
    "\n",
    "prediction = grid_decision_tree_classifier.predict(X_test)\n",
    "print(f'테스트 데이터 세트 정확도: {accuracy_score(y_test, prediction)}')\n",
    "\n",
    "# refit 된 객체는 best_estimator_로 가져올 수 있으며,\n",
    "# 이미 grid_decision_tree_classifier객체를 GridSearchCV로 작업하여 생성했기 때문에\n",
    "# 결과는 똑같이 나온다.\n",
    "estimator = grid_decision_tree_classifier.best_estimator_\n",
    "prediction = estimator.predict(X_test)\n",
    "print(f'테스트 데이터 세트 정확도: {accuracy_score(y_test, prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b87fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255741ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
